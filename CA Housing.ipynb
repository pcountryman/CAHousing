{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA census housing data\n",
    "\n",
    "The goal of this project is to predict the location of a median house value in California based on census parameters, such as median age, income, and average population of a region.\n",
    "\n",
    "We will use both classification and regression algorithms to fit our data, though I suspect regression algorithms will lead to a better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data\n",
    "\n",
    "I will be working with a [dataset available on kaggle](https://www.kaggle.com/camnugent/california-housing-prices). The housing data collected from the 1990 census."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T14:34:27.219975Z",
     "start_time": "2020-08-20T14:34:25.786264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Import the kaggle dataset\n",
    "house = pd.read_csv('housing.csv')\n",
    "# Drop any row that contains NaN values\n",
    "housing = house.dropna(axis=0)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I don't have official training in natural language processing, I will get rid of the *ocean_proximity* column, and assess the longitude and latitude based only on the numerical values of the remaining input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T14:34:50.570640Z",
     "start_time": "2020-08-20T14:34:50.551679Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0       322.0       126.0         8.3252            452600.0  \n",
       "1      2401.0      1138.0         8.3014            358500.0  \n",
       "2       496.0       177.0         7.2574            352100.0  \n",
       "3       558.0       219.0         5.6431            341300.0  \n",
       "4       565.0       259.0         3.8462            342200.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing2 = housing.drop('ocean_proximity', axis=1)\n",
    "housing2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is unclear at this point what algorithms we will be using to fit our data. Many algorithms require normalized data to function properly, so let's go ahead and normalize each column of data. To do this, I will divide each column by it's maximum value (or minimum in the case of longitude)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T14:36:28.449395Z",
     "start_time": "2020-08-20T14:36:28.380571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.982951</td>\n",
       "      <td>0.902980</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.022380</td>\n",
       "      <td>0.020016</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.020717</td>\n",
       "      <td>0.555010</td>\n",
       "      <td>0.905198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.982871</td>\n",
       "      <td>0.902503</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.180544</td>\n",
       "      <td>0.171606</td>\n",
       "      <td>0.067289</td>\n",
       "      <td>0.187110</td>\n",
       "      <td>0.553423</td>\n",
       "      <td>0.716999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.983032</td>\n",
       "      <td>0.902265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037309</td>\n",
       "      <td>0.029480</td>\n",
       "      <td>0.013901</td>\n",
       "      <td>0.029102</td>\n",
       "      <td>0.483823</td>\n",
       "      <td>0.704199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.983112</td>\n",
       "      <td>0.902265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032401</td>\n",
       "      <td>0.036462</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>0.036008</td>\n",
       "      <td>0.376204</td>\n",
       "      <td>0.682599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.983112</td>\n",
       "      <td>0.902265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041378</td>\n",
       "      <td>0.043445</td>\n",
       "      <td>0.015834</td>\n",
       "      <td>0.042585</td>\n",
       "      <td>0.256412</td>\n",
       "      <td>0.684399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>0.973784</td>\n",
       "      <td>0.941120</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.042345</td>\n",
       "      <td>0.058029</td>\n",
       "      <td>0.023681</td>\n",
       "      <td>0.054258</td>\n",
       "      <td>0.104019</td>\n",
       "      <td>0.156200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>0.974749</td>\n",
       "      <td>0.941359</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.017726</td>\n",
       "      <td>0.023274</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>0.170452</td>\n",
       "      <td>0.154200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>0.974829</td>\n",
       "      <td>0.939928</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>0.075252</td>\n",
       "      <td>0.028222</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.184600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>0.975633</td>\n",
       "      <td>0.939928</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.047304</td>\n",
       "      <td>0.063460</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>0.057382</td>\n",
       "      <td>0.124479</td>\n",
       "      <td>0.169400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>0.974990</td>\n",
       "      <td>0.938498</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.070829</td>\n",
       "      <td>0.095578</td>\n",
       "      <td>0.038871</td>\n",
       "      <td>0.087142</td>\n",
       "      <td>0.159239</td>\n",
       "      <td>0.178800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20433 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0       0.982951  0.902980            0.788462     0.022380        0.020016   \n",
       "1       0.982871  0.902503            0.403846     0.180544        0.171606   \n",
       "2       0.983032  0.902265            1.000000     0.037309        0.029480   \n",
       "3       0.983112  0.902265            1.000000     0.032401        0.036462   \n",
       "4       0.983112  0.902265            1.000000     0.041378        0.043445   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "20635   0.973784  0.941120            0.480769     0.042345        0.058029   \n",
       "20636   0.974749  0.941359            0.346154     0.017726        0.023274   \n",
       "20637   0.974829  0.939928            0.326923     0.057325        0.075252   \n",
       "20638   0.975633  0.939928            0.346154     0.047304        0.063460   \n",
       "20639   0.974990  0.938498            0.307692     0.070829        0.095578   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "0        0.009024    0.020717       0.555010            0.905198  \n",
       "1        0.067289    0.187110       0.553423            0.716999  \n",
       "2        0.013901    0.029102       0.483823            0.704199  \n",
       "3        0.015638    0.036008       0.376204            0.682599  \n",
       "4        0.015834    0.042585       0.256412            0.684399  \n",
       "...           ...         ...            ...                 ...  \n",
       "20635    0.023681    0.054258       0.104019            0.156200  \n",
       "20636    0.009977    0.018744       0.170452            0.154200  \n",
       "20637    0.028222    0.071194       0.113333            0.184600  \n",
       "20638    0.020767    0.057382       0.124479            0.169400  \n",
       "20639    0.038871    0.087142       0.159239            0.178800  \n",
       "\n",
       "[20433 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing3 = housing2.copy()\n",
    "housing3.housing_median_age = housing3.housing_median_age/housing3.housing_median_age.max()\n",
    "housing3.total_rooms = housing3.total_rooms/housing3.total_rooms.max()\n",
    "housing3.total_bedrooms = housing3.total_bedrooms/housing3.total_bedrooms.max()\n",
    "housing3.population = housing3.population/housing3.population.max()\n",
    "housing3.households = housing3.households/housing3.households.max()\n",
    "housing3.median_income = housing3.median_income/housing3.median_income.max()\n",
    "housing3.median_house_value = housing3.median_house_value/housing3.median_house_value.max()\n",
    "housing3.longitude = housing3.longitude/housing3.longitude.min()\n",
    "housing3.latitude = housing3.latitude/housing3.latitude.max()\n",
    "housing3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the data\n",
    "\n",
    "Now that our data contains normalized parameters, it is time to try different algorithms that will attempt to predict the median house value.\n",
    "\n",
    "Unless stated otherwise, I will split our 20433 data points into a training set and test set, with a 75/25 split respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with ridge, lasso, and elastic net\n",
    "\n",
    "The median house value is unlikely to be a linear combination of our input variables, but it is a good place to start for simplicity.\n",
    "\n",
    "Linear regression attempts to minimize the sum of the absolute error of each coefficient used in fitting the model. Lasso regression also includes a second term to be minimized, alpha times the absolute magnitude of each input parameter. This allows the parameters weight to be zero for input parameters with negligible influence.\n",
    "\n",
    "Ridge regression also utilizes a least squares fitting and penalty feature. The Ridge regression penalty feature is alpha times the input parameter squared. This second term cannot be zero, however it should still reduce the model complexity.\n",
    "\n",
    "In both cases, the alpha factor controls how much each individual input parameter has on our output parameters, instead of assuming the sum of squares for each parameter should be equally weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T14:49:23.799275Z",
     "start_time": "2020-08-20T14:49:23.769355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fit score for linear model on training data is 0.429422589442498\n",
      "The fit score for linear model on test data is 0.4142418047384244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nplt.scatter(range(0,len(y_test)), y_test, label='True test value')\\nplt.scatter(range(0,len(lrmodelpredicty)), lrmodelpredicty, label='Predicted test value')\\nplt.legend()\\nplt.xlabel('index')\\nplt.ylabel('ave hous price')\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = housing3.iloc[:,:-1]\n",
    "y = housing3.iloc[:,-1:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "lrmodel = LinearRegression().fit(X_train, y_train)\n",
    "lrmodelpredicttrain = lrmodel.predict(X_train)\n",
    "lrmodelpredicty = lrmodel.predict(X_test)\n",
    "print(\"The fit score for linear model on training data is\", r2_score(lrmodelpredicttrain, y_train))\n",
    "print(\"The fit score for linear model on test data is\", r2_score(lrmodelpredicty, y_test))\n",
    "'''\n",
    "plt.scatter(range(0,len(y_test)), y_test, label='True test value')\n",
    "plt.scatter(range(0,len(lrmodelpredicty)), lrmodelpredicty, label='Predicted test value')\n",
    "plt.legend()\n",
    "plt.xlabel('index')\n",
    "plt.ylabel('ave hous price')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we suspected, a simple linear model doesn't seem to fit our dataset very well. Let's give the Ridge regression a try and see if that improves our fit quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T14:52:26.718207Z",
     "start_time": "2020-08-20T14:52:26.649392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long weight</th>\n",
       "      <th>lat weight</th>\n",
       "      <th>housing_median_age weight</th>\n",
       "      <th>total_rooms weight</th>\n",
       "      <th>total_bedrooms weight</th>\n",
       "      <th>population weight</th>\n",
       "      <th>households weight</th>\n",
       "      <th>median_income weight</th>\n",
       "      <th>Training</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>10.740944</td>\n",
       "      <td>-3.588182</td>\n",
       "      <td>0.123431</td>\n",
       "      <td>-0.611730</td>\n",
       "      <td>1.488216</td>\n",
       "      <td>-2.577095</td>\n",
       "      <td>0.461844</td>\n",
       "      <td>1.202239</td>\n",
       "      <td>0.429392</td>\n",
       "      <td>0.414209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>10.717718</td>\n",
       "      <td>-3.581132</td>\n",
       "      <td>0.123594</td>\n",
       "      <td>-0.613079</td>\n",
       "      <td>1.487029</td>\n",
       "      <td>-2.576328</td>\n",
       "      <td>0.464048</td>\n",
       "      <td>1.202635</td>\n",
       "      <td>0.429117</td>\n",
       "      <td>0.413912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>10.490923</td>\n",
       "      <td>-3.512288</td>\n",
       "      <td>0.125189</td>\n",
       "      <td>-0.626194</td>\n",
       "      <td>1.475465</td>\n",
       "      <td>-2.568645</td>\n",
       "      <td>0.485391</td>\n",
       "      <td>1.206489</td>\n",
       "      <td>0.426391</td>\n",
       "      <td>0.410966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>8.662250</td>\n",
       "      <td>-2.956891</td>\n",
       "      <td>0.138148</td>\n",
       "      <td>-0.726989</td>\n",
       "      <td>1.384353</td>\n",
       "      <td>-2.490950</td>\n",
       "      <td>0.643833</td>\n",
       "      <td>1.237149</td>\n",
       "      <td>0.401517</td>\n",
       "      <td>0.384057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>3.181598</td>\n",
       "      <td>-1.286162</td>\n",
       "      <td>0.179306</td>\n",
       "      <td>-0.859441</td>\n",
       "      <td>1.069142</td>\n",
       "      <td>-1.877755</td>\n",
       "      <td>0.843254</td>\n",
       "      <td>1.312691</td>\n",
       "      <td>0.282230</td>\n",
       "      <td>0.254539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>0.410605</td>\n",
       "      <td>-0.401378</td>\n",
       "      <td>0.202266</td>\n",
       "      <td>-0.232306</td>\n",
       "      <td>0.424943</td>\n",
       "      <td>-0.526648</td>\n",
       "      <td>0.365549</td>\n",
       "      <td>1.250059</td>\n",
       "      <td>0.074272</td>\n",
       "      <td>0.032159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         long weight  lat weight  housing_median_age weight  \\\n",
       "0.0001     10.740944   -3.588182                   0.123431   \n",
       "0.0010     10.717718   -3.581132                   0.123594   \n",
       "0.0100     10.490923   -3.512288                   0.125189   \n",
       "0.1000      8.662250   -2.956891                   0.138148   \n",
       "1.0000      3.181598   -1.286162                   0.179306   \n",
       "10.0000     0.410605   -0.401378                   0.202266   \n",
       "\n",
       "         total_rooms weight  total_bedrooms weight  population weight  \\\n",
       "0.0001            -0.611730               1.488216          -2.577095   \n",
       "0.0010            -0.613079               1.487029          -2.576328   \n",
       "0.0100            -0.626194               1.475465          -2.568645   \n",
       "0.1000            -0.726989               1.384353          -2.490950   \n",
       "1.0000            -0.859441               1.069142          -1.877755   \n",
       "10.0000           -0.232306               0.424943          -0.526648   \n",
       "\n",
       "         households weight  median_income weight  Training      Test  \n",
       "0.0001            0.461844              1.202239  0.429392  0.414209  \n",
       "0.0010            0.464048              1.202635  0.429117  0.413912  \n",
       "0.0100            0.485391              1.206489  0.426391  0.410966  \n",
       "0.1000            0.643833              1.237149  0.401517  0.384057  \n",
       "1.0000            0.843254              1.312691  0.282230  0.254539  \n",
       "10.0000           0.365549              1.250059  0.074272  0.032159  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = housing3.iloc[:,:-1]\n",
    "y = housing3.iloc[:,-1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# Create empty dictionary to store fit scores in, convert to dataframe at end\n",
    "ridgefits = {}\n",
    "\n",
    "# List of alpha values\n",
    "alpha = [0.0001,0.001,0.01,0.1,1,10]\n",
    "dummyweight = {}\n",
    "for i in alpha:\n",
    "    ridgemodel = Ridge(alpha = i).fit(X_train, y_train)\n",
    "    ridgemodelpredicttrain = ridgemodel.predict(X_train)\n",
    "    ridgemodelpredicty = ridgemodel.predict(X_test)\n",
    "    # Dictionary is train: test\n",
    "    ridgefits[i] = [r2_score(ridgemodelpredicttrain, y_train), r2_score(ridgemodelpredicty, y_test)]\n",
    "    dummyweight[i] = ridgemodel.coef_[0]\n",
    "\n",
    "dummydata = pd.DataFrame.from_dict(ridgefits).T\n",
    "dummyfits = dummydata.rename(columns = {0 : 'Training', 1 : 'Test'})\n",
    "dummydata = pd.DataFrame.from_dict(dummyweight).T\n",
    "ridgeweights = dummydata.rename(columns={0 : 'long weight', 1 : 'lat weight', 2 : 'housing_median_age weight', \n",
    "                                         3 : 'total_rooms weight', 4 : 'total_bedrooms weight', 5 : 'population weight', \n",
    "                                         6 : 'households weight', 7 : 'median_income weight'})\n",
    "ridgeweights['Training'] = dummyfits.Training\n",
    "ridgeweights['Test'] = dummyfits.Test\n",
    "ridgeweights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing our $\\alpha$ factor decreases our quality of fit, as represented by the $r^2$ test value dropping as $\\alpha$ increases.\n",
    "\n",
    "It is worth noting that the fit is best when:\n",
    "- longitude is strongly weighted\n",
    "- median income, househoulds and total_bedrooms are weakly weighted\n",
    "- latitude and population are weakly negatively weighted\n",
    "\n",
    "Again, our fit isn't great, so let's try the lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T14:58:51.675241Z",
     "start_time": "2020-08-20T14:58:51.537607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long weight</th>\n",
       "      <th>lat weight</th>\n",
       "      <th>housing_median_age weight</th>\n",
       "      <th>total_rooms weight</th>\n",
       "      <th>total_bedrooms weight</th>\n",
       "      <th>population weight</th>\n",
       "      <th>households weight</th>\n",
       "      <th>median_income weight</th>\n",
       "      <th>Training</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000001</th>\n",
       "      <td>10.705008</td>\n",
       "      <td>-3.577162</td>\n",
       "      <td>0.123717</td>\n",
       "      <td>-0.608799</td>\n",
       "      <td>1.484115</td>\n",
       "      <td>-2.571203</td>\n",
       "      <td>0.461149</td>\n",
       "      <td>1.202384</td>\n",
       "      <td>4.287209e-01</td>\n",
       "      <td>0.413472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>10.358201</td>\n",
       "      <td>-3.470852</td>\n",
       "      <td>0.126457</td>\n",
       "      <td>-0.584256</td>\n",
       "      <td>1.446860</td>\n",
       "      <td>-2.516935</td>\n",
       "      <td>0.456425</td>\n",
       "      <td>1.204134</td>\n",
       "      <td>4.222555e-01</td>\n",
       "      <td>0.406391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000100</th>\n",
       "      <td>6.888669</td>\n",
       "      <td>-2.406735</td>\n",
       "      <td>0.153874</td>\n",
       "      <td>-0.346551</td>\n",
       "      <td>1.087773</td>\n",
       "      <td>-1.966618</td>\n",
       "      <td>0.398263</td>\n",
       "      <td>1.222461</td>\n",
       "      <td>3.423450e-01</td>\n",
       "      <td>0.319722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007777</td>\n",
       "      <td>0.177447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175418</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.227564</td>\n",
       "      <td>-5.086316e-02</td>\n",
       "      <td>-0.095766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630302</td>\n",
       "      <td>-4.339055e+00</td>\n",
       "      <td>-4.530819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.727857e+31</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          long weight  lat weight  housing_median_age weight  \\\n",
       "0.000001    10.705008   -3.577162                   0.123717   \n",
       "0.000010    10.358201   -3.470852                   0.126457   \n",
       "0.000100     6.888669   -2.406735                   0.153874   \n",
       "0.001000     0.000000   -0.007777                   0.177447   \n",
       "0.010000     0.000000   -0.000000                   0.000000   \n",
       "0.100000     0.000000   -0.000000                   0.000000   \n",
       "\n",
       "          total_rooms weight  total_bedrooms weight  population weight  \\\n",
       "0.000001           -0.608799               1.484115          -2.571203   \n",
       "0.000010           -0.584256               1.446860          -2.516935   \n",
       "0.000100           -0.346551               1.087773          -1.966618   \n",
       "0.001000            0.000000               0.175418          -0.000000   \n",
       "0.010000            0.000000               0.000000          -0.000000   \n",
       "0.100000            0.000000               0.000000          -0.000000   \n",
       "\n",
       "          households weight  median_income weight      Training      Test  \n",
       "0.000001           0.461149              1.202384  4.287209e-01  0.413472  \n",
       "0.000010           0.456425              1.204134  4.222555e-01  0.406391  \n",
       "0.000100           0.398263              1.222461  3.423450e-01  0.319722  \n",
       "0.001000           0.000000              1.227564 -5.086316e-02 -0.095766  \n",
       "0.010000           0.000000              0.630302 -4.339055e+00 -4.530819  \n",
       "0.100000           0.000000              0.000000 -1.727857e+31  0.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = housing3.iloc[:,:-1]\n",
    "y = housing3.iloc[:,-1:]\n",
    "\n",
    "# Create empty dictionary to store fit scores in, convert to dataframe at end\n",
    "lassofits = {}\n",
    "\n",
    "# List of alpha values\n",
    "alpha = [0.000001,0.00001,0.0001,0.001,0.01,0.1]\n",
    "dummyweight = {}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "for i in alpha:\n",
    "    lassomodel = Lasso(alpha = i, max_iter=2000).fit(X_train, y_train)\n",
    "    lassomodelpredicttrain = lassomodel.predict(X_train)\n",
    "    lassomodelpredicty = lassomodel.predict(X_test)\n",
    "    # Dictionary is train: test\n",
    "    lassofits[i] = [r2_score(lassomodelpredicttrain, y_train), r2_score(lassomodelpredicty, y_test)]\n",
    "    dummyweight[i] = lassomodel.coef_\n",
    "dummydata = pd.DataFrame.from_dict(lassofits).T\n",
    "dummyfits = dummydata.rename(columns = {0 : 'Training', 1 : 'Test'})\n",
    "dummydata = pd.DataFrame.from_dict(dummyweight).T\n",
    "lassoweights = dummydata.rename(columns={0 : 'long weight', 1 : 'lat weight', 2 : 'housing_median_age weight', \n",
    "                                         3 : 'total_rooms weight', 4 : 'total_bedrooms weight', 5 : 'population weight', \n",
    "                                         6 : 'households weight', 7 : 'median_income weight'})\n",
    "lassoweights['Training'] = dummyfits.Training\n",
    "lassoweights['Test'] = dummyfits.Test\n",
    "lassoweights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso quickly quashes all input parameters down to zero weight. This isn't extrodinarily helpful.\n",
    "\n",
    "Let's try one last combination of ridge and lasso by applying the elastic net algorithm. Elastic net regression attempts to minimize the least squares regression, and both correction factors provided by Lasso and Ridge.\n",
    "\n",
    "Here $\\alpha$ is similar to the Lasso error correction parameter. The l1 ratio correction parameters can vary between 0 and 1. When the l1 parameter is set to zero, the penalty is an L2 penalty. For l1 parameter = 1, the penalty is an L1 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T15:14:46.390641Z",
     "start_time": "2020-08-20T15:14:45.665999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>alpha</th>\n",
       "      <th>0.000001</th>\n",
       "      <th>0.000010</th>\n",
       "      <th>0.000100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1 ratio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.001000</th>\n",
       "      <td>[0.42791788608690096, 0.3928168742576158]</td>\n",
       "      <td>[0.3921898379741442, 0.35383678661682916]</td>\n",
       "      <td>[0.25258744878352013, 0.20237298029140882]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002154</th>\n",
       "      <td>[0.42792228672743193, 0.3928216845899686]</td>\n",
       "      <td>[0.39222152021175294, 0.35387119857455285]</td>\n",
       "      <td>[0.25261764613099713, 0.2024058447704672]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004642</th>\n",
       "      <td>[0.4279317681860212, 0.3928320486992247]</td>\n",
       "      <td>[0.39228982219292474, 0.3539453849188261]</td>\n",
       "      <td>[0.2526829147655588, 0.20247683840870667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010000</th>\n",
       "      <td>[0.427952198087888, 0.39285438051217847]</td>\n",
       "      <td>[0.39243718372894376, 0.3541054456590208]</td>\n",
       "      <td>[0.2528245733907465, 0.20263070021671759]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.021544</th>\n",
       "      <td>[0.4279962257869149, 0.39290250779586744]</td>\n",
       "      <td>[0.3927556364857163, 0.35445134746720663]</td>\n",
       "      <td>[0.25313737655573443, 0.2029676688397215]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.046416</th>\n",
       "      <td>[0.4280911393231007, 0.3930062605094642]</td>\n",
       "      <td>[0.3934462685510218, 0.35520155202483816]</td>\n",
       "      <td>[0.2538195829464822, 0.20370839490853032]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100000</th>\n",
       "      <td>[0.42829589790667355, 0.3932300976545766]</td>\n",
       "      <td>[0.39495558705488676, 0.3568412331525772]</td>\n",
       "      <td>[0.2553699516171234, 0.20539264242000854]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.215443</th>\n",
       "      <td>[0.42873830749248987, 0.39371377588190826]</td>\n",
       "      <td>[0.3983097303921741, 0.360486068820408]</td>\n",
       "      <td>[0.2591505755078102, 0.20950109936841832]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.464159</th>\n",
       "      <td>[0.429697344791654, 0.3947624782384457]</td>\n",
       "      <td>[0.4060428595208484, 0.36889524592485057]</td>\n",
       "      <td>[0.2703177934154475, 0.2216215876165395]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000</th>\n",
       "      <td>[0.43179089850824626, 0.3970528412204838]</td>\n",
       "      <td>[0.42536285227654635, 0.38995403711720633]</td>\n",
       "      <td>[0.3458700137116397, 0.3032407370354767]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "alpha                                       0.000001  \\\n",
       "l1 ratio                                               \n",
       "0.001000   [0.42791788608690096, 0.3928168742576158]   \n",
       "0.002154   [0.42792228672743193, 0.3928216845899686]   \n",
       "0.004642    [0.4279317681860212, 0.3928320486992247]   \n",
       "0.010000    [0.427952198087888, 0.39285438051217847]   \n",
       "0.021544   [0.4279962257869149, 0.39290250779586744]   \n",
       "0.046416    [0.4280911393231007, 0.3930062605094642]   \n",
       "0.100000   [0.42829589790667355, 0.3932300976545766]   \n",
       "0.215443  [0.42873830749248987, 0.39371377588190826]   \n",
       "0.464159     [0.429697344791654, 0.3947624782384457]   \n",
       "1.000000   [0.43179089850824626, 0.3970528412204838]   \n",
       "\n",
       "alpha                                       0.000010  \\\n",
       "l1 ratio                                               \n",
       "0.001000   [0.3921898379741442, 0.35383678661682916]   \n",
       "0.002154  [0.39222152021175294, 0.35387119857455285]   \n",
       "0.004642   [0.39228982219292474, 0.3539453849188261]   \n",
       "0.010000   [0.39243718372894376, 0.3541054456590208]   \n",
       "0.021544   [0.3927556364857163, 0.35445134746720663]   \n",
       "0.046416   [0.3934462685510218, 0.35520155202483816]   \n",
       "0.100000   [0.39495558705488676, 0.3568412331525772]   \n",
       "0.215443     [0.3983097303921741, 0.360486068820408]   \n",
       "0.464159   [0.4060428595208484, 0.36889524592485057]   \n",
       "1.000000  [0.42536285227654635, 0.38995403711720633]   \n",
       "\n",
       "alpha                                       0.000100  \n",
       "l1 ratio                                              \n",
       "0.001000  [0.25258744878352013, 0.20237298029140882]  \n",
       "0.002154   [0.25261764613099713, 0.2024058447704672]  \n",
       "0.004642   [0.2526829147655588, 0.20247683840870667]  \n",
       "0.010000   [0.2528245733907465, 0.20263070021671759]  \n",
       "0.021544   [0.25313737655573443, 0.2029676688397215]  \n",
       "0.046416   [0.2538195829464822, 0.20370839490853032]  \n",
       "0.100000   [0.2553699516171234, 0.20539264242000854]  \n",
       "0.215443   [0.2591505755078102, 0.20950109936841832]  \n",
       "0.464159    [0.2703177934154475, 0.2216215876165395]  \n",
       "1.000000    [0.3458700137116397, 0.3032407370354767]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = housing3.iloc[:,:-1]\n",
    "y = housing3.iloc[:,-1:]\n",
    "\n",
    "# Create empty dictionary to store fit scores in, convert to dataframe at end\n",
    "netfits = {}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "alpha = [0.000001, 0.00001, 0.0001]\n",
    "\n",
    "l1 = np.logspace(-3,0,10, base=10)\n",
    "for i in alpha:\n",
    "    # Create/reset a counter for l1 loop\n",
    "    l1fits = {}\n",
    "    for _ in l1:\n",
    "        netmodel = ElasticNet(alpha = i, l1_ratio = _, max_iter=6000).fit(X_train, y_train)\n",
    "        netmodelpredicttrain = netmodel.predict(X_train)\n",
    "        netmodelpredicty = netmodel.predict(X_test)\n",
    "        # Dictionary is train: test\n",
    "        l1fits[_] = [r2_score(netmodelpredicttrain, y_train), r2_score(netmodelpredicty, y_test)]\n",
    "    netfits[i] = l1fits\n",
    "allnetfits = pd.DataFrame.from_dict(netfits)\n",
    "allnetfits.index.name = 'l1 ratio'\n",
    "allnetfits.columns.name = 'alpha'\n",
    "allnetfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table values can be read as (training $r^2$ value, test $r^2$ value).\n",
    "\n",
    "There is no significant change in the fit as we vary the l1 ratio. Increasing the alpha correction factor quickly degrades the fit, similar to what we observed in the Lasso only fits.\n",
    "\n",
    "As we suspected, linear fits of our input parameters are not great predictors for the median housing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T15:19:47.552037Z",
     "start_time": "2020-08-20T15:19:41.820935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.373488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.811184</td>\n",
       "      <td>0.424235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.713603</td>\n",
       "      <td>0.425102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.655582</td>\n",
       "      <td>0.424833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.610369</td>\n",
       "      <td>0.419887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.580213</td>\n",
       "      <td>0.412902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.552503</td>\n",
       "      <td>0.413893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.530952</td>\n",
       "      <td>0.403537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.513216</td>\n",
       "      <td>0.394408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.496661</td>\n",
       "      <td>0.391319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.481097</td>\n",
       "      <td>0.388980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.467721</td>\n",
       "      <td>0.386235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.455998</td>\n",
       "      <td>0.379497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.444501</td>\n",
       "      <td>0.373447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.435110</td>\n",
       "      <td>0.369549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Training      Test\n",
       "1   1.000000  0.373488\n",
       "2   0.811184  0.424235\n",
       "3   0.713603  0.425102\n",
       "4   0.655582  0.424833\n",
       "5   0.610369  0.419887\n",
       "6   0.580213  0.412902\n",
       "7   0.552503  0.413893\n",
       "8   0.530952  0.403537\n",
       "9   0.513216  0.394408\n",
       "10  0.496661  0.391319\n",
       "11  0.481097  0.388980\n",
       "12  0.467721  0.386235\n",
       "13  0.455998  0.379497\n",
       "14  0.444501  0.373447\n",
       "15  0.435110  0.369549"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = housing3.iloc[:,:-1]\n",
    "y = housing3.iloc[:,-1:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "knnfits = {}\n",
    "dummyweight = {}\n",
    "neighbors = np.linspace(1,15,15, dtype='int')\n",
    "for i in neighbors:\n",
    "    knnmodel = KNeighborsRegressor(n_neighbors = i).fit(X_train, y_train)\n",
    "    knnmodelpredicttrain = knnmodel.predict(X_train)\n",
    "    knnmodelpredicty = knnmodel.predict(X_test)\n",
    "    # Dictionary is train: test\n",
    "    knnfits[i] = [r2_score(knnmodelpredicttrain, y_train), r2_score(knnmodelpredicty, y_test)]\n",
    "dummydata = pd.DataFrame.from_dict(knnfits).T\n",
    "dummyfits = dummydata.rename(columns = {0 : 'Training', 1 : 'Test'})\n",
    "\n",
    "plt.scatter(neighbors, dummyfits.Training, label='train')\n",
    "plt.scatter(neighbors, dummyfits.Test, label='test')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel(\"N nearest neighbors\")\n",
    "plt.ylabel(\"R squared\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "dummyfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN model has a slightly higher fit than our linear regression for 2-4 neighbors. I might be able to acheive better results by running the model many times with different seeds, but the fit value is still low enough that I think we should try other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression\n",
    "\n",
    "Polynomial fitting allows for higher-order and coupled input parameter weights to be a factor in determining the final fit. For instance, while *households* may not correlate strongly to our desired result, perhaps $(households)^2$ does, or $households \\cdot population$. Polynomial fitting allows us to test non-linear combinations of our input parameters, and determine their relative weights to median housing value.\n",
    "\n",
    "Let's try fitting our data to different polynomials of first through fifth degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T15:27:09.769531Z",
     "start_time": "2020-08-20T15:27:06.324948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R squared</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N degree Polynomial</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.414242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.554849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.613410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.482877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     R squared\n",
       "N degree Polynomial           \n",
       "1                     0.414242\n",
       "2                     0.554849\n",
       "3                     0.613410\n",
       "4                     0.482877\n",
       "5                     0.000905"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's try higher order fits using polynomials\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "degree = []\n",
    "polymodpredictiontrainlist = []\n",
    "polymodpredictylist = []\n",
    "\n",
    "X = housing3.iloc[:,:-1]\n",
    "y = housing3.iloc[:,-1:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "for i in range(1,6):\n",
    "    degree.append(i)\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    x_poly = poly.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_poly,y, random_state=0)\n",
    "\n",
    "    polymodel = LinearRegression().fit(X_train, y_train)\n",
    "    polymodelpredicttrain = polymodel.predict(X_train)\n",
    "    polymodelpredicty = polymodel.predict(X_test)\n",
    "    polymodpredictiontrainlist.append(r2_score(polymodelpredicttrain, y_train))\n",
    "    polymodpredictylist.append(r2_score(polymodelpredicty, y_test))\n",
    "    #print(polymodelpredicty, y_test\n",
    "\n",
    "plt.scatter(degree, polymodpredictiontrainlist, label='train')\n",
    "plt.scatter(degree, polymodpredictylist, label='test')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel(\"N degree polynomial\")\n",
    "plt.ylabel(\"R squared\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "pd.Series(polymodpredictylist, index = range(1,6))\n",
    "\n",
    "polyfits = pd.DataFrame(list(zip(polymodpredictylist, range(1,8))), columns = ['R squared', 'N degree Polynomial'])\n",
    "polyfits = polyfits.set_index('N degree Polynomial')\n",
    "polyfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a 3rd degree polynomial has managed to fit our test data better than any previous model. While the fit on the training data continues to increase past this point, this is due to overfitting, and leads to a decrease in the test fit.\n",
    "\n",
    "Let's quickly try the elastic net on our 3rd degree polynomial to see if we can increase our fit even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T15:35:11.216211Z",
     "start_time": "2020-08-20T15:30:05.459401Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 121.97524585901917, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 121.95660797959441, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 121.91646575850517, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 121.83003834738331, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 121.64417972729639, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 121.24426595463058, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 120.39515219612056, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 118.55023838661889, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 114.56497848499704, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 105.59082887053304, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 128.3756733880167, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 128.10275390097556, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 127.51907243892516, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 126.28141857685232, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 123.70286716248968, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 118.36419150134181, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 108.68497323594268, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.82599054636441, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67.25746418530028, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.025146806403214, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 136.01734349586872, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 128.05880535079436, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 110.0648743203058, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 79.45057713617044, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.648043488576064, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.013679047452058, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.581032503403918, tolerance: 0.08217053229002265\n",
      "  positive)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3372111687077677, tolerance: 0.08217053229002265\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>alpha</th>\n",
       "      <th>0.000001</th>\n",
       "      <th>0.000010</th>\n",
       "      <th>0.000100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1 ratio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.001000</th>\n",
       "      <td>[0.582314262974504, 0.5738542712588965]</td>\n",
       "      <td>[0.5527647025923492, 0.5447629551457976]</td>\n",
       "      <td>[0.4844207624547515, 0.47892672097331856]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002154</th>\n",
       "      <td>[0.582320896013659, 0.5738611741964329]</td>\n",
       "      <td>[0.552756092163762, 0.5447522163031139]</td>\n",
       "      <td>[0.48432605869454426, 0.47883614956589193]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004642</th>\n",
       "      <td>[0.582335216152275, 0.5738760802330347]</td>\n",
       "      <td>[0.5527374776189218, 0.5447290035886889]</td>\n",
       "      <td>[0.4841220452970493, 0.4786415145972327]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010000</th>\n",
       "      <td>[0.5823662296179275, 0.5739083969261685]</td>\n",
       "      <td>[0.5526970184269003, 0.5446785794466167]</td>\n",
       "      <td>[0.483680607415072, 0.47822138959103166]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.021544</th>\n",
       "      <td>[0.5824343081006622, 0.5739788848588838]</td>\n",
       "      <td>[0.5526079940784066, 0.544568389485597]</td>\n",
       "      <td>[0.4827240408907384, 0.4773048592143363]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.046416</th>\n",
       "      <td>[0.5825815432786748, 0.5741338055515732]</td>\n",
       "      <td>[0.5524023962094365, 0.5443156152242273]</td>\n",
       "      <td>[0.48064655491702934, 0.47530698999097654]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100000</th>\n",
       "      <td>[0.5829256976355197, 0.5744917346134939]</td>\n",
       "      <td>[0.5520126329343444, 0.5438068101447429]</td>\n",
       "      <td>[0.47610345470299087, 0.47097220280925023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.215443</th>\n",
       "      <td>[0.5837178789055043, 0.57527519450733]</td>\n",
       "      <td>[0.5511148451965615, 0.5426779427357327]</td>\n",
       "      <td>[0.4663337031279362, 0.461825007887233]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.464159</th>\n",
       "      <td>[0.5859171866043658, 0.5773920077385873]</td>\n",
       "      <td>[0.5493991075451043, 0.5404981912860309]</td>\n",
       "      <td>[0.44695938886746045, 0.4441904802024027]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000</th>\n",
       "      <td>[0.6004557929030176, 0.5899792067453583]</td>\n",
       "      <td>[0.5506862189410395, 0.5411424112040604]</td>\n",
       "      <td>[0.41792426416049067, 0.4184658118409137]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "alpha                                     0.000001  \\\n",
       "l1 ratio                                             \n",
       "0.001000   [0.582314262974504, 0.5738542712588965]   \n",
       "0.002154   [0.582320896013659, 0.5738611741964329]   \n",
       "0.004642   [0.582335216152275, 0.5738760802330347]   \n",
       "0.010000  [0.5823662296179275, 0.5739083969261685]   \n",
       "0.021544  [0.5824343081006622, 0.5739788848588838]   \n",
       "0.046416  [0.5825815432786748, 0.5741338055515732]   \n",
       "0.100000  [0.5829256976355197, 0.5744917346134939]   \n",
       "0.215443    [0.5837178789055043, 0.57527519450733]   \n",
       "0.464159  [0.5859171866043658, 0.5773920077385873]   \n",
       "1.000000  [0.6004557929030176, 0.5899792067453583]   \n",
       "\n",
       "alpha                                     0.000010  \\\n",
       "l1 ratio                                             \n",
       "0.001000  [0.5527647025923492, 0.5447629551457976]   \n",
       "0.002154   [0.552756092163762, 0.5447522163031139]   \n",
       "0.004642  [0.5527374776189218, 0.5447290035886889]   \n",
       "0.010000  [0.5526970184269003, 0.5446785794466167]   \n",
       "0.021544   [0.5526079940784066, 0.544568389485597]   \n",
       "0.046416  [0.5524023962094365, 0.5443156152242273]   \n",
       "0.100000  [0.5520126329343444, 0.5438068101447429]   \n",
       "0.215443  [0.5511148451965615, 0.5426779427357327]   \n",
       "0.464159  [0.5493991075451043, 0.5404981912860309]   \n",
       "1.000000  [0.5506862189410395, 0.5411424112040604]   \n",
       "\n",
       "alpha                                       0.000100  \n",
       "l1 ratio                                              \n",
       "0.001000   [0.4844207624547515, 0.47892672097331856]  \n",
       "0.002154  [0.48432605869454426, 0.47883614956589193]  \n",
       "0.004642    [0.4841220452970493, 0.4786415145972327]  \n",
       "0.010000    [0.483680607415072, 0.47822138959103166]  \n",
       "0.021544    [0.4827240408907384, 0.4773048592143363]  \n",
       "0.046416  [0.48064655491702934, 0.47530698999097654]  \n",
       "0.100000  [0.47610345470299087, 0.47097220280925023]  \n",
       "0.215443     [0.4663337031279362, 0.461825007887233]  \n",
       "0.464159   [0.44695938886746045, 0.4441904802024027]  \n",
       "1.000000   [0.41792426416049067, 0.4184658118409137]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = housing3.iloc[:,:-1]\n",
    "y = housing3.iloc[:,-1:]\n",
    "\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "x_poly = poly.fit_transform(X)\n",
    "# Create empty dictionary to store fit scores in, convert to dataframe at end\n",
    "netfits = {}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_poly, y)\n",
    "\n",
    "alpha = [0.000001,0.00001,0.0001]\n",
    "l1 = np.logspace(-3,0,10, base=10)\n",
    "for i in alpha:\n",
    "    l1fits = {}\n",
    "    for _ in l1:\n",
    "        netmodel = ElasticNet(alpha = i, l1_ratio = _, max_iter=4000).fit(X_train, y_train)\n",
    "        netmodelpredicttrain = netmodel.predict(X_train)\n",
    "        netmodelpredicty = netmodel.predict(X_test)\n",
    "        # Dictionary is train: test\n",
    "        l1fits[_] = [r2_score(netmodelpredicttrain, y_train), r2_score(netmodelpredicty, y_test)]\n",
    "    netfits[i] = l1fits\n",
    "allnetfits = pd.DataFrame.from_dict(netfits)\n",
    "allnetfits.index.name = 'l1 ratio'\n",
    "allnetfits.columns.name = 'alpha'\n",
    "allnetfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table values can be read as (training $r^2$ value, test $r^2$ value).\n",
    "\n",
    "Similar to what we saw previously, our fit values in our test set are more or less invariant over the l1 ratio, and decrease as alpha increases.\n",
    "\n",
    "At this point, without more iterations, we've capped out our polynomial regression capabilities. We did see an improvement over the linear regression, but let us continue to explore algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machines\n",
    "\n",
    "It is possible that a few datapoints are causing a large skew to our fitted models, and linear regression fitting techniques are poorly suited for this data set. In order to accomodate for larger margins of error for individual data points, we are going to try support vector machines to fit our data set.\n",
    "\n",
    "It is important to note that support vector regression analysis does not actually transform the data when it evaluates fits, thus it is computationally less intensive than polynomial regression.\n",
    "\n",
    "The C value in the SVR controls the strength of regularization. Large C values fit the training data as well as possible (less regularization), while smaller C values are more tolerant of errors in individual data points (more regularization). C must be positive, and the strength of the squared l2 penalty is inversely proportional to C.\n",
    "\n",
    "The $\\gamma$ factor determines the similarity factor for data points. Large $\\gamma$ increases the influence of other nearby data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T15:59:18.411498Z",
     "start_time": "2020-08-20T15:58:03.254560Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>C value</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>[-1.29532985591604, -1.222443518049067]</td>\n",
       "      <td>[0.04616501860538735, 0.08824709506991735]</td>\n",
       "      <td>[0.27032593185418863, 0.3067276648170797]</td>\n",
       "      <td>[0.40600709515289635, 0.437643298060976]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>[0.049063514033386935, 0.09248956874244507]</td>\n",
       "      <td>[0.28567015177815924, 0.3222071943600171]</td>\n",
       "      <td>[0.4464853439788723, 0.4742427758143626]</td>\n",
       "      <td>[0.5196552845944109, 0.5437471162849646]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>[0.33553573581465257, 0.3751024924325286]</td>\n",
       "      <td>[0.5035809516283947, 0.5316752324810166]</td>\n",
       "      <td>[0.5753101098424249, 0.5934472135014823]</td>\n",
       "      <td>[0.6071019662752006, 0.6216608587038421]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "C value                                            0.1    \\\n",
       "gamma value                                                \n",
       "0.01             [-1.29532985591604, -1.222443518049067]   \n",
       "0.10         [0.049063514033386935, 0.09248956874244507]   \n",
       "1.00           [0.33553573581465257, 0.3751024924325286]   \n",
       "\n",
       "C value                                           1.0    \\\n",
       "gamma value                                               \n",
       "0.01         [0.04616501860538735, 0.08824709506991735]   \n",
       "0.10          [0.28567015177815924, 0.3222071943600171]   \n",
       "1.00           [0.5035809516283947, 0.5316752324810166]   \n",
       "\n",
       "C value                                          10.0   \\\n",
       "gamma value                                              \n",
       "0.01         [0.27032593185418863, 0.3067276648170797]   \n",
       "0.10          [0.4464853439788723, 0.4742427758143626]   \n",
       "1.00          [0.5753101098424249, 0.5934472135014823]   \n",
       "\n",
       "C value                                         100.0  \n",
       "gamma value                                            \n",
       "0.01         [0.40600709515289635, 0.437643298060976]  \n",
       "0.10         [0.5196552845944109, 0.5437471162849646]  \n",
       "1.00         [0.6071019662752006, 0.6216608587038421]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = housing3.iloc[:,:-1]\n",
    "y = housing3.iloc[:,-1:]\n",
    "\n",
    "# Create empty dictionary to store fit scores in, convert to dataframe at end\n",
    "svrfits = {}\n",
    "\n",
    "#lat fit\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "cvalues = np.logspace(-1,2,4, base=10)\n",
    "gammavalues = np.logspace(-2,0,3, base=10)\n",
    "for i in cvalues:\n",
    "    gammavaluesfits = {}\n",
    "    for _ in gammavalues:\n",
    "        svrmodel = SVR(kernel = 'rbf', C = i, gamma = _).fit(X_train, y_train)\n",
    "        svrmodelpredicttrain = svrmodel.predict(X_train)\n",
    "        svrmodelpredicty = svrmodel.predict(X_test)\n",
    "        # Dictionary is train: test\n",
    "        gammavaluesfits[_] = [r2_score(svrmodelpredicttrain, y_train), r2_score(svrmodelpredicty, y_test)]\n",
    "    svrfits[i] = gammavaluesfits\n",
    "allsvrfits = pd.DataFrame.from_dict(svrfits)\n",
    "allsvrfits.index.name = 'gamma value'\n",
    "allsvrfits.columns.name = 'C value'\n",
    "allsvrfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table values can be read as (training $r^2$ value, test $r^2$ value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
